{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K8GGkiaBFhZ",
        "outputId": "bbb17760-c18f-4edc-928e-846e20c9eeb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/320.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m317.4/320.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoJS52X9Bk05"
      },
      "source": [
        "Import OpenAI and create a connection with the help of the API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swc5GTvPBXVb",
        "outputId": "2d69a6d9-08c7-4efa-d67c-bc7d723f0f45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7924de8219f0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"add api key here\")\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja-iupNw2MO4"
      },
      "source": [
        "## **Create the Assistant**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckvEK2TVCNMf"
      },
      "source": [
        "Upload the file containing the screenplay of the episode.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bEgTwZ_CN1M"
      },
      "outputs": [],
      "source": [
        "uploaded_file = client.files.create(\n",
        "    file = (\"/content/Victory_of_the_Daleks.txt\", 'rb'),\n",
        "    purpose='assistants'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ISixgQ-sqyH"
      },
      "source": [
        "Check that file has been uploaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1undZfWLsq8d",
        "outputId": "45cdb4a1-2cda-47ec-9553-10ff508f64f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-Z3YAaQJBvElpPO9ratWKTb9q', bytes=2, created_at=1716063806, filename='/content/Victory_of_the_Daleks.txt', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uploaded_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDHzzAB2tMjw"
      },
      "source": [
        "Copy from https://platform.openai.com/docs/assistants/overview the code from Step 1 for the assistant and modify as needed.\n",
        "Change tools to retrieval and add the model that you are using.\n",
        "I had to comment out file_ids and tools, as it was not supported by the model that I used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPruQynktMsV"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Friendly Dalek\",\n",
        "  instructions=\"You are a Dalek, who is friendly as in the provided text file, and offering help and tea.\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  #file_ids=[uploaded_file.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io1108IH1dIA"
      },
      "source": [
        "## **Create the Thread**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTzOz6jY2VLs"
      },
      "source": [
        "Create the thread and run to display the thread ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEsjDAi41dPi",
        "outputId": "02ccb6bf-494b-4b83-d458-f23373102855"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Thread(id='thread_x7xiXUqtUkcE3xEGr67KLvOI', created_at=1716063813, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thread = client.beta.threads.create()\n",
        "thread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoGRZSYW2qqR"
      },
      "source": [
        "Add a message to the the thread.\n",
        "Run to display the message ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f909nSM2qzY"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"What are you doing here?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9jKF7uS38k9",
        "outputId": "1b8cc6f5-46d2-4df1-aa26-76a32ed99f35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_voQiQenpncpv8KkMgsDcmGPL', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What are you doing here?'), type='text')], created_at=1716063817, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_x7xiXUqtUkcE3xEGr67KLvOI')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8MmljEX4S8L"
      },
      "source": [
        "Run the assistant\n",
        "Create the run, so that the assistant can read the thread and generate the response.\n",
        "Here without streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23tuFpXV4TFM"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        "  #instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HtnMRei4zE8"
      },
      "source": [
        "Check Run status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FxySXHz4zNp",
        "outputId": "42b56e41-4102-48b7-b0c0-2702977e9ae4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Run(id='run_iLcNLCRIKrHx0SpICC3SUyVX', assistant_id='asst_wT7JDXPLKBtkCoQ3tIhu9Sgj', cancelled_at=None, completed_at=None, created_at=1716063824, expires_at=None, failed_at=1716063830, incomplete_details=None, instructions='You are a Dalek, who is friendly as in the provided text file, and offering help and tea.', last_error=LastError(code='rate_limit_exceeded', message='You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.'), max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo', object='thread.run', required_action=None, response_format='auto', started_at=1716063824, status='failed', thread_id='thread_x7xiXUqtUkcE3xEGr67KLvOI', tool_choice='auto', tools=[FileSearchTool(type='file_search')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0), temperature=1.0, top_p=1.0, tool_resources={})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R-bS2bA5IgN"
      },
      "source": [
        "Describe the message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEDDdJ7t5Ip7",
        "outputId": "c99d725d-bb72-471a-ae17-8458416e1e25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_voQiQenpncpv8KkMgsDcmGPL', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What are you doing here?'), type='text')], created_at=1716063817, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_x7xiXUqtUkcE3xEGr67KLvOI')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwfIcBJN5OzP"
      },
      "source": [
        "Get latest messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA8MODe45O8d",
        "outputId": "495d0935-ea36-4499-afc0-c21996be819d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[Message](data=[Message(id='msg_voQiQenpncpv8KkMgsDcmGPL', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What are you doing here?'), type='text')], created_at=1716063817, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_x7xiXUqtUkcE3xEGr67KLvOI')], object='list', first_id='msg_voQiQenpncpv8KkMgsDcmGPL', last_id='msg_voQiQenpncpv8KkMgsDcmGPL', has_more=False)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "messages"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
